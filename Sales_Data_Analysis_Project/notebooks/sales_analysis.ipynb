{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37f1cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA ENGINEER - DATA CLEANING PROCESS\n",
      "============================================================\n",
      "\n",
      "\n",
      "1. IMPORTING DATASET...\n",
      "----------------------------------------\n",
      "Dataset imported successfully!\n",
      "Shape of dataset: (100, 8)\n",
      "Number of rows: 100\n",
      "Number of columns: 8\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "  Order_ID              Product         Region  Units_Sold  Unit_Price  \\\n",
      "0   ORD001              Printer        Limpopo          45        2985   \n",
      "1   ORD002           Headphones   Western Cape          16       15076   \n",
      "2   ORD003               Laptop   Western Cape          45       14860   \n",
      "3   ORD004  External Hard Drive  KwaZulu-Natal          21       16237   \n",
      "4   ORD005           Smartphone   Western Cape          41        9420   \n",
      "\n",
      "   Revenue Sales_Rep  Order_Date  \n",
      "0   134325     Rep-2  2024-03-28  \n",
      "1   241216    Rep-18  2024-04-11  \n",
      "2   668700    Rep-16  2024-05-18  \n",
      "3   340977     Rep-3  2024-05-16  \n",
      "4   386220    Rep-17  2024-02-21  \n",
      "\n",
      "\n",
      "2. INITIAL DATA EXPLORATION...\n",
      "----------------------------------------\n",
      "Column Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Order_ID    100 non-null    object\n",
      " 1   Product     100 non-null    object\n",
      " 2   Region      100 non-null    object\n",
      " 3   Units_Sold  100 non-null    int64 \n",
      " 4   Unit_Price  100 non-null    int64 \n",
      " 5   Revenue     100 non-null    int64 \n",
      " 6   Sales_Rep   100 non-null    object\n",
      " 7   Order_Date  100 non-null    object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 6.4+ KB\n",
      "None\n",
      "\n",
      "\n",
      "Statistical Summary:\n",
      "       Units_Sold    Unit_Price       Revenue\n",
      "count  100.000000    100.000000  1.000000e+02\n",
      "mean    28.230000  12616.570000  3.529534e+05\n",
      "std     14.159877   6927.580312  2.632478e+05\n",
      "min      2.000000    927.000000  7.914000e+03\n",
      "25%     16.750000   6916.000000  1.103550e+05\n",
      "50%     27.500000  12380.500000  3.248750e+05\n",
      "75%     42.250000  17670.250000  5.286000e+05\n",
      "max     49.000000  24995.000000  1.040204e+06\n",
      "\n",
      "\n",
      "Unique values in categorical columns:\n",
      "Products: ['Printer' 'Headphones' 'Laptop' 'External Hard Drive' 'Smartphone'\n",
      " 'Smartwatch' 'Tablet']\n",
      "Regions: ['Limpopo' 'Western Cape' 'KwaZulu-Natal' 'North West' 'Free State'\n",
      " 'Gauteng' 'Eastern Cape']\n",
      "Sales Representatives: ['Rep-2' 'Rep-18' 'Rep-16' 'Rep-3' 'Rep-17' 'Rep-19' 'Rep-1' 'Rep-7'\n",
      " 'Rep-15' 'Rep-14' 'Rep-12' 'Rep-20' 'Rep-13' 'Rep-11' 'Rep-8' 'Rep-4'\n",
      " 'Rep-9' 'Rep-6' 'Rep-5' 'Rep-10']\n",
      "Number of unique orders: 100\n",
      "\n",
      "\n",
      "3. CHECKING FOR DATA QUALITY ISSUES...\n",
      "----------------------------------------\n",
      "3.1 Missing Values Check:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Values, Percentage]\n",
      "Index: []\n",
      "✓ No missing values found!\n",
      "\n",
      "\n",
      "3.2 Duplicates Check:\n",
      "Total duplicate rows: 0\n",
      "Duplicate Order IDs: 0\n",
      "✓ No duplicates found!\n",
      "\n",
      "\n",
      "3.3 Data Types Check:\n",
      "Order_ID      object\n",
      "Product       object\n",
      "Region        object\n",
      "Units_Sold     int64\n",
      "Unit_Price     int64\n",
      "Revenue        int64\n",
      "Sales_Rep     object\n",
      "Order_Date    object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "3.4 Data Consistency Checks:\n",
      "Checking Revenue calculation consistency...\n",
      "Revenue discrepancies found: 0\n",
      "✓ All revenue calculations are consistent!\n",
      "\n",
      "\n",
      "4. PERFORMING DATA CLEANING...\n",
      "----------------------------------------\n",
      "4.1 Removed temporary calculated column\n",
      "\n",
      "\n",
      "4.2 Converting Order_Date to datetime format...\n",
      "✓ Order_Date converted to datetime: datetime64[ns]\n",
      "Date range: 2024-01-01 00:00:00 to 2024-06-29 00:00:00\n",
      "\n",
      "\n",
      "4.3 Missing value handling (demonstration):\n",
      "✓ No missing values to handle!\n",
      "\n",
      "\n",
      "4.4 Duplicate handling (demonstration):\n",
      "✓ No duplicates to remove!\n",
      "\n",
      "\n",
      "4.5 Final data type validation:\n",
      "Order_ID              object\n",
      "Product               object\n",
      "Region                object\n",
      "Units_Sold             int64\n",
      "Unit_Price             int64\n",
      "Revenue                int64\n",
      "Sales_Rep             object\n",
      "Order_Date    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "\n",
      "4.6 Outlier detection (summary):\n",
      "Units_Sold: 0 potential outliers detected\n",
      "Unit_Price: 0 potential outliers detected\n",
      "Revenue: 0 potential outliers detected\n",
      "\n",
      "\n",
      "5. CLEANED DATASET SUMMARY\n",
      "----------------------------------------\n",
      "Final shape: (100, 8)\n",
      "\n",
      "First 3 rows of cleaned dataset:\n",
      "  Order_ID     Product        Region  Units_Sold  Unit_Price  Revenue  \\\n",
      "0   ORD001     Printer       Limpopo          45        2985   134325   \n",
      "1   ORD002  Headphones  Western Cape          16       15076   241216   \n",
      "2   ORD003      Laptop  Western Cape          45       14860   668700   \n",
      "\n",
      "  Sales_Rep Order_Date  \n",
      "0     Rep-2 2024-03-28  \n",
      "1    Rep-18 2024-04-11  \n",
      "2    Rep-16 2024-05-18  \n",
      "\n",
      "Data types after cleaning:\n",
      "Order_ID              object\n",
      "Product               object\n",
      "Region                object\n",
      "Units_Sold             int64\n",
      "Unit_Price             int64\n",
      "Revenue                int64\n",
      "Sales_Rep             object\n",
      "Order_Date    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "============================================================\n",
      "DATA CLEANING COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "PYTHON ANALYST - KPI CALCULATIONS\n",
      "============================================================\n",
      "\n",
      "\n",
      "Added time-based columns for analysis:\n",
      "  Order_Date  Order_Month Month_Name  Order_Year\n",
      "0 2024-03-28            3      March        2024\n",
      "1 2024-04-11            4      April        2024\n",
      "2 2024-05-18            5        May        2024\n",
      "3 2024-05-16            5        May        2024\n",
      "4 2024-02-21            2   February        2024\n",
      "\n",
      "\n",
      "2. CALCULATING KEY PERFORMANCE INDICATORS\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "KPI 1: TOTAL REVENUE\n",
      "--------------------\n",
      "Total Revenue: R 35,295,338.00\n",
      "\n",
      "\n",
      "KPI 2: AVERAGE UNITS SOLD PER ORDER\n",
      "--------------------\n",
      "Average Units Sold per Order: 28.23\n",
      "\n",
      "\n",
      "KPI 3: TOTAL REVENUE PER REGION\n",
      "--------------------\n",
      "Revenue by Region (Descending Order):\n",
      "  Western Cape: R 9,346,198.00\n",
      "  Gauteng: R 6,231,531.00\n",
      "  North West: R 6,201,288.00\n",
      "  Limpopo: R 3,614,655.00\n",
      "  KwaZulu-Natal: R 3,560,630.00\n",
      "  Free State: R 3,359,398.00\n",
      "  Eastern Cape: R 2,981,638.00\n",
      "\n",
      "\n",
      "KPI 4: HIGHEST REVENUE-GENERATING SALES REPRESENTATIVE\n",
      "--------------------\n",
      "Top 5 Sales Representatives by Revenue:\n",
      "  1. Rep-19: R 2,889,294.00\n",
      "  2. Rep-14: R 2,859,882.00\n",
      "  3. Rep-1: R 2,856,551.00\n",
      "  4. Rep-3: R 2,686,043.00\n",
      "  5. Rep-13: R 2,460,993.00\n",
      "\n",
      " Highest Revenue Generating Sales Rep: Rep-19\n",
      "   Total Revenue Generated: R 2,889,294.00\n",
      "\n",
      "\n",
      "KPI 5: TOP 3 PRODUCTS BY TOTAL UNITS SOLD\n",
      "--------------------\n",
      "Top 3 Products by Units Sold:\n",
      "  1. Smartwatch: 542 units\n",
      "  2. Tablet: 511 units\n",
      "  3. Smartphone: 437 units\n",
      "\n",
      "\n",
      "3. EXPORTING RESULTS\n",
      "----------------------------------------\n",
      "✓ Files exported successfully!\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# sales_analysis.ipynb - CLEAN VERSION\n",
    "\n",
    "\"\"\"\n",
    "SALES DATA ANALYSIS PROJECT\n",
    "================================\n",
    "Python Lead (Data Engineer)\n",
    "Python Analyst (KPI Calculator)\n",
    "\"\"\"\n",
    "\n",
    "# ============================================\n",
    "# DATA ENGINEER - DATA CLEANING\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA ENGINEER - DATA CLEANING PROCESS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 1. IMPORT THE DATASET\n",
    "# -----------------------------------------------------------------\n",
    "print(\"1. IMPORTING DATASET...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load the CSV file using the correct path\n",
    "df = pd.read_csv(r'C:\\Users\\CAPACITI-JHB\\OneDrive\\Desktop\\Sales-data-analysis\\Sales_Data_Analysis_Project\\data\\Week-2-Sales-Data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset imported successfully!\")\n",
    "print(f\"Shape of dataset: {df.shape}\")  # (rows, columns)\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(f\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 2. INITIAL DATA EXPLORATION\n",
    "# -----------------------------------------------------------------\n",
    "print(\"2. INITIAL DATA EXPLORATION...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Display column names and data types\n",
    "print(\"Column Information:\")\n",
    "print(df.info())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Display basic statistics for numerical columns\n",
    "print(\"Statistical Summary:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Display unique values in categorical columns\n",
    "print(\"Unique values in categorical columns:\")\n",
    "print(f\"Products: {df['Product'].unique()}\")\n",
    "print(f\"Regions: {df['Region'].unique()}\")\n",
    "print(f\"Sales Representatives: {df['Sales_Rep'].unique()}\")\n",
    "print(f\"Number of unique orders: {df['Order_ID'].nunique()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3. CHECK FOR DATA QUALITY ISSUES\n",
    "# -----------------------------------------------------------------\n",
    "print(\"3. CHECKING FOR DATA QUALITY ISSUES...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 3.1 Check for missing values\n",
    "print(\"3.1 Missing Values Check:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_report = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "print(missing_report[missing_report['Missing Values'] > 0])\n",
    "if missing_report[missing_report['Missing Values'] > 0].empty:\n",
    "    print(\"✓ No missing values found!\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3.2 Check for duplicates\n",
    "print(\"3.2 Duplicates Check:\")\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "duplicate_order_ids = df['Order_ID'].duplicated().sum()\n",
    "print(f\"Total duplicate rows: {duplicate_rows}\")\n",
    "print(f\"Duplicate Order IDs: {duplicate_order_ids}\")\n",
    "if duplicate_rows == 0 and duplicate_order_ids == 0:\n",
    "    print(\"✓ No duplicates found!\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3.3 Check data types\n",
    "print(\"3.3 Data Types Check:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3.4 Check for potential data inconsistencies\n",
    "print(\"3.4 Data Consistency Checks:\")\n",
    "print(\"Checking Revenue calculation consistency...\")\n",
    "# Calculate expected revenue from Units_Sold * Unit_Price\n",
    "df['Calculated_Revenue'] = df['Units_Sold'] * df['Unit_Price']\n",
    "\n",
    "# Compare with existing Revenue column\n",
    "revenue_discrepancies = df[df['Revenue'] != df['Calculated_Revenue']]\n",
    "print(f\"Revenue discrepancies found: {len(revenue_discrepancies)}\")\n",
    "if len(revenue_discrepancies) == 0:\n",
    "    print(\"✓ All revenue calculations are consistent!\")\n",
    "else:\n",
    "    print(\"\\nRevenue discrepancies:\")\n",
    "    print(revenue_discrepancies[['Order_ID', 'Units_Sold', 'Unit_Price', 'Revenue', 'Calculated_Revenue']])\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 4. DATA CLEANING PROCESS\n",
    "# -----------------------------------------------------------------\n",
    "print(\"4. PERFORMING DATA CLEANING...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create a copy of the original dataframe for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 4.1 Remove the temporary calculated column\n",
    "df_clean = df_clean.drop('Calculated_Revenue', axis=1)\n",
    "print(\"4.1 Removed temporary calculated column\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4.2 Convert Order_Date to proper datetime format\n",
    "print(\"4.2 Converting Order_Date to datetime format...\")\n",
    "df_clean['Order_Date'] = pd.to_datetime(df_clean['Order_Date'])\n",
    "print(f\"✓ Order_Date converted to datetime: {df_clean['Order_Date'].dtype}\")\n",
    "print(f\"Date range: {df_clean['Order_Date'].min()} to {df_clean['Order_Date'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4.3 Check for and handle any missing values (if any were found)\n",
    "# Since we found no missing values, this is just for demonstration\n",
    "print(\"4.3 Missing value handling (demonstration):\")\n",
    "if df_clean.isnull().sum().sum() > 0:\n",
    "    print(\"Handling missing values...\")\n",
    "    # For numerical columns, fill with median\n",
    "    # For categorical columns, fill with mode\n",
    "    numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "    print(\"Missing values handled.\")\n",
    "else:\n",
    "    print(\"✓ No missing values to handle!\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4.4 Remove duplicates (if any were found)\n",
    "print(\"4.4 Duplicate handling (demonstration):\")\n",
    "initial_rows = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "final_rows = len(df_clean)\n",
    "duplicates_removed = initial_rows - final_rows\n",
    "\n",
    "if duplicates_removed > 0:\n",
    "    print(f\"Removed {duplicates_removed} duplicate rows\")\n",
    "else:\n",
    "    print(\"✓ No duplicates to remove!\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4.5 Validate data types\n",
    "print(\"4.5 Final data type validation:\")\n",
    "print(df_clean.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4.6 Check for outliers in numerical columns\n",
    "print(\"4.6 Outlier detection (summary):\")\n",
    "numerical_cols = ['Units_Sold', 'Unit_Price', 'Revenue']\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)]\n",
    "    print(f\"{col}: {len(outliers)} potential outliers detected\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 5. FINAL CLEANED DATASET SUMMARY\n",
    "# -----------------------------------------------------------------\n",
    "print(\"5. CLEANED DATASET SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Final shape: {df_clean.shape}\")\n",
    "print(f\"\\nFirst 3 rows of cleaned dataset:\")\n",
    "print(df_clean.head(3))\n",
    "print(f\"\\nData types after cleaning:\")\n",
    "print(df_clean.dtypes)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA CLEANING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60 + \"\\n\\n\")\n",
    "\n",
    "# ============================================\n",
    "# PYTHON ANALYST - KPI CALCULATIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PYTHON ANALYST - KPI CALCULATIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 1. SETUP FOR ANALYSIS\n",
    "# -----------------------------------------------------------------\n",
    "# We'll use the cleaned dataframe for all calculations\n",
    "df_analysis = df_clean.copy()\n",
    "\n",
    "# Add month and year columns for time-based analysis\n",
    "df_analysis['Order_Month'] = df_analysis['Order_Date'].dt.month\n",
    "df_analysis['Order_Year'] = df_analysis['Order_Date'].dt.year\n",
    "df_analysis['Month_Name'] = df_analysis['Order_Date'].dt.strftime('%B')\n",
    "\n",
    "print(\"Added time-based columns for analysis:\")\n",
    "print(df_analysis[['Order_Date', 'Order_Month', 'Month_Name', 'Order_Year']].head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 2. CALCULATE KEY PERFORMANCE INDICATORS (KPIs)\n",
    "# -----------------------------------------------------------------\n",
    "print(\"2. CALCULATING KEY PERFORMANCE INDICATORS\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\\n\")\n",
    "\n",
    "# KPI 1: Total revenue for the entire dataset\n",
    "print(\"KPI 1: TOTAL REVENUE\")\n",
    "print(\"-\" * 20)\n",
    "total_revenue = df_analysis['Revenue'].sum()\n",
    "print(f\"Total Revenue: R {total_revenue:,.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# KPI 2: Average units sold per order\n",
    "print(\"KPI 2: AVERAGE UNITS SOLD PER ORDER\")\n",
    "print(\"-\" * 20)\n",
    "avg_units_sold = df_analysis['Units_Sold'].mean()\n",
    "print(f\"Average Units Sold per Order: {avg_units_sold:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# KPI 3: Total revenue per region\n",
    "print(\"KPI 3: TOTAL REVENUE PER REGION\")\n",
    "print(\"-\" * 20)\n",
    "revenue_by_region = df_analysis.groupby('Region')['Revenue'].sum().sort_values(ascending=False)\n",
    "print(\"Revenue by Region (Descending Order):\")\n",
    "for region, revenue in revenue_by_region.items():\n",
    "    print(f\"  {region}: R {revenue:,.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# KPI 4: Highest revenue-generating sales representative\n",
    "print(\"KPI 4: HIGHEST REVENUE-GENERATING SALES REPRESENTATIVE\")\n",
    "print(\"-\" * 20)\n",
    "revenue_by_rep = df_analysis.groupby('Sales_Rep')['Revenue'].sum().sort_values(ascending=False)\n",
    "print(\"Top 5 Sales Representatives by Revenue:\")\n",
    "for i, (rep, revenue) in enumerate(revenue_by_rep.head().items(), 1):\n",
    "    print(f\"  {i}. {rep}: R {revenue:,.2f}\")\n",
    "\n",
    "# Get the top rep\n",
    "top_rep = revenue_by_rep.index[0]\n",
    "top_rep_revenue = revenue_by_rep.iloc[0]\n",
    "print(f\"\\n Highest Revenue Generating Sales Rep: {top_rep}\")\n",
    "print(f\"   Total Revenue Generated: R {top_rep_revenue:,.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# KPI 5: Top 3 products by total units sold\n",
    "print(\"KPI 5: TOP 3 PRODUCTS BY TOTAL UNITS SOLD\")\n",
    "print(\"-\" * 20)\n",
    "units_by_product = df_analysis.groupby('Product')['Units_Sold'].sum().sort_values(ascending=False)\n",
    "top_3_products = units_by_product.head(3)\n",
    "print(\"Top 3 Products by Units Sold:\")\n",
    "for i, (product, units) in enumerate(top_3_products.items(), 1):\n",
    "    print(f\"  {i}. {product}: {units:,} units\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3. EXPORT RESULTS\n",
    "# -----------------------------------------------------------------\n",
    "print(\"3. EXPORTING RESULTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create DataFrames for export\n",
    "kpi_summary = pd.DataFrame({\n",
    "    'KPI': ['Total Revenue', 'Average Units per Order', 'Top Sales Rep', 'Top Product'],\n",
    "    'Value': [\n",
    "        f\"R {total_revenue:,.2f}\",\n",
    "        f\"{avg_units_sold:.2f}\",\n",
    "        top_rep,\n",
    "        top_3_products.index[0]\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Export to CSV\n",
    "kpi_summary.to_csv('kpi_summary.csv', index=False)\n",
    "pd.DataFrame(revenue_by_region).to_csv('revenue_by_region.csv')\n",
    "pd.DataFrame(units_by_product).to_csv('units_by_product.csv')\n",
    "\n",
    "print(\"✓ Files exported successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETED!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
